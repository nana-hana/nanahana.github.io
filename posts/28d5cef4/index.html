<!-- build time:Thu Mar 26 2020 20:30:48 GMT+0800 (GMT+08:00) --><!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="概率论,数理统计,概率论与数理统计"><meta name="description" content=""><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>概率论与数理统计 | 喵窝</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/css/my.css"><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="喵窝" type="application/atom+xml"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><div><img src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/medias/loading.gif" alt="" data-original="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">喵窝</span></div></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/medias/loading.gif" alt="" data-original="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">喵窝</div><div class="logo-desc">Never really desperate, only the lost of the soul.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li><div class="divider"></div></li><li><a href="https://github.com/nana-hana/" class="waves-effect waves-light" target="_blank"><i class="fab fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#9e71bf;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/nana-hana/" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/medias/featureimages/2.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">概率论与数理统计</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px}#toc-content .is-active-link{color:#42b983}#toc-content .is-active-link::before{background-color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E6%95%B0%E5%AD%A6/"><span class="chip bg-color">数学</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%95%B0%E5%AD%A6/" class="post-category">数学</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2020-03-07</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2020-03-18</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 5.6k</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><p><img src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/medias/loading.gif" alt="" data-original="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/post_img/probabilityAndStatistics.png"></p><h2 id="概率论的基本概念"><a href="#概率论的基本概念" class="headerlink" title="概率论的基本概念"></a>概率论的基本概念</h2><h3 id="随机试验"><a href="#随机试验" class="headerlink" title="随机试验"></a>随机试验</h3><p>随机试验：$\begin{cases} 在相同条件下可重复。\\结果不止一个。\\无法预测。 \end{cases}$</p><h3 id="样本空间、随机事件"><a href="#样本空间、随机事件" class="headerlink" title="样本空间、随机事件"></a>样本空间、随机事件</h3><ol><li>样本空间：所有基本事件的集合。</li><li>样本点：样本空间的元素。</li><li>$A\subset B$：事件B包含事件A。</li><li>$A\bigcup B=\{x|x∈A 或 x∈B\}$：事件A与事件B的和事件（也可以记为$A+B$），即A，B中至少一个发生，事件$A\bigcup B$发生。</li><li>$A\bigcap B=\{x|x∈A 且 x∈B\}$：事件A与事件B的积事件（也可以记为$AB$），即仅当A，B同时发生时，事件$A\bigcup B$发生。</li><li>$A-B=\{x|x∈A 且 x∈B\}$：事件A与事件B的差事件，即当且仅当A发生、B不发生时，事件$A-B$发生。</li><li>$A\bigcap B=\emptyset$：事件A与B是互不相容的（或互斥的），即事件A与事件B不能同时发生。</li><li>$A\bigcup B=S$且$A\bigcap B=\emptyset$，事件A与事件B互为逆事件（或事件A与事件B互为对立事件），即事件A、B中必有一个发生，且仅有一个发生（A的对立事件记为$\hat{A}$，$\hat{A}=S-A$，S为总事件）。</li></ol><h3 id="频率与概率"><a href="#频率与概率" class="headerlink" title="频率与概率"></a>频率与概率</h3><ol><li>频率：描述了事件发生的频繁程度，即大量实验统计。</li><li>概率：在一次试验中发生的可能性大小的数。频率的稳定值即统计概率。</li><li>公理化：$\begin{cases} 非负性，概率不为负\\规范性，P(S)=1\\可列可加性 \end{cases}$。</li><li>概率性质：$\begin{cases} p(\emptyset)=0。\\P(A_1+A_2+\dots+A_n)=P(A_1)+P(A_2)+\dots+P(A_n)。\\若A\subset B，则P(B-A)=P(B)-P(A)，P(B)≥P(A)。\\对于任一事件A，P(A)≤1。\\对于任一事件A，P(\hat{A})=1-P(A)。\\P(A\bigcup B)=P(A)+P(B)-P(AB)=P(A)+P(B-AB)。 \end{cases}$</li></ol><h3 id="古典概型"><a href="#古典概型" class="headerlink" title="古典概型"></a>古典概型</h3><ol><li>古典概型：$\begin{cases} 样本点个数有限。\\每个基本事件发生的概率相同。 \end{cases}$，也可称为等可能概型。</li><li>$P(A)=\frac{有利样本点}{样本总数}$，例如$\frac{骰子偶数点数3}{总骰子数6}$。</li><li>不重复排列：$\begin{cases}P_n^m=n(n-1)(n-2)\dots(n-m+1)=\frac{n!}{(n-m)!}\\P_n^n=n(n-1)×\dots×3×2×1=n! \end{cases}$。<br>重复排列：$\begin{cases}C_n^m=\frac{P_n^m}{m!}=\frac{n!}{m!(n-m)!}\\C_n^m=C_n^{n-m}\\C_n^0=C_n^n=1 \end{cases}$。</li><li>几何概型：$p(A)=\frac{\mu(G)}{\mu(S)}$，$\mu$表几何区域内的一种度量（如线段中即长度），与古典概型性质唯一不同的在于几何概型拥有完全可加性，古典概型是有限可加性。</li></ol><h3 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h3><ol><li>条件概率：S样本空间，A，B两个事件，其中$P(B)&gt;0$，称$P(A|B)=\frac{P(AB)}{P(B)}$为在事件A发生的条件下事件B发生的条件概率。</li><li>乘法公式：$P(ABC)=P(A)P(B|A)P(C|AB)$，即先发生了A，然后在A发生的条件下发生了B，最后在AB发生的条件下发生了C。n项的话依次类推。</li><li>全概率公式：$A_1,A_2\dots A_n$是E的完备事件组（互不相容，并是S），$P(A_i)&gt;0$，$P(B)=\sum_{i=1}^nP(A_i)P(B|A_i)$。知原因推结果。</li><li>贝叶斯公式：$A_1,A_2\dots A_n$是E的完备事件组，B是任一事件，$P(A_i)&gt;0$，$P(B)&gt;0$，$P(A_k|B)=\frac{P(A_k)P(B|A_k)}{\sum_{i=1}{n}P(A_i)P(B|A_i}=\frac{P(A_kB)}{P(B)}$。知结果推原因。</li></ol><h3 id="独立性"><a href="#独立性" class="headerlink" title="独立性"></a>独立性</h3><ol><li>若$P(A)&gt;0$，$P(B)&gt;0$，$P(A|B)=P(A)$或$P(AB)=P(A)P(B)$，即A的概率不受B发生与否的影响称为独立性。</li><li>若事件A与B相互独立，则A与$\hat{B}$，$\hat{A}$与B，$\hat{A}$与$\hat{B}$都相互独立。</li><li>A，B，C三个事件，若满足等式：$\begin{cases} P(AB)=P(A)P(B)\\P(AC)=P(A)P(C)\\P(BC)=P(B)P(C)\\P(ABC)=P(A)P(B)P(C) \end{cases}$，则事件A，B，C相互独立。</li></ol><h2 id="随机变量及其分布"><a href="#随机变量及其分布" class="headerlink" title="随机变量及其分布"></a>随机变量及其分布</h2><h3 id="随机变量"><a href="#随机变量" class="headerlink" title="随机变量"></a>随机变量</h3><ol><li>在样本空间$S={e}$中，$X=X(e)$每一个样本都对应一个实值单值函数，则称$X=X(e)$为随机变量。</li><li>离散型：有限个或无限可列个。</li><li>连续型（非离散型）：取值一个或多个区间。</li></ol><h3 id="离散型随机变量及其分布律"><a href="#离散型随机变量及其分布律" class="headerlink" title="离散型随机变量及其分布律"></a>离散型随机变量及其分布律</h3><ol><li>离散型随机变量X所有可能取的值为$x_k(k=1,2,\dots)$，X取各个可能值的概率，即事件$\{X=x_k\}$的概率为$P\{X=x_k\}=p_k$。且$p_k≥0$，$\sum_{k=1}^\infty p_k=1$。</li><li>伯努利试验：试验只有A和$\hat{A}$两种可能。</li><li>n重伯努利试验：将伯努利试验重复n次，试验之间彼此独立。</li><li>$(0-1)$分布：随机变量X只能取0与1两个值，其分布律为$P\{X=k\}=p^k(1-p)^{1-k}, k=0,1（0&lt;p&lt;1）$。</li><li>几何分布：设$P(A)=p$，第k次首次发生，即前$k-1$次未发生，则$P\{X=k\}=(1-p)^{k-1}p，k=1,2,3,\dots$，记为$X\sim G(p)$。</li><li>二项分布：即n重伯努利试验，记为$X\sim B(n, p)$。$P(A)=p$，n次试验发生了k次，则$P\{X=k\}=C_n^kp^k(1-p)^{n-k}，k=0,1,\dots,n$。当$n=1$时，二项分布化为$(0-1)$分布。二项分布最可能值：$\begin{cases} (n+1)p不为整数，[(n+1)p]达到最大值。\\(n+1)p是整数，(n+1)p和(n+1)p-1都是最大值。 \end{cases}$</li><li>泊松分布：$P\{X=k\}=\frac{\lambda^ke^{-\lambda}}{k!}，k=0,1,\dots$，其中$\lambda&gt;0$，记为$X\sim P(\lambda)$或$X\sim \pi(\lambda)$。</li><li>超几何分布：不放回抽样试验，N个元素，$N_1$属于第一类，$N_2$属于第二类，取n个，X：n个中属于第一类的个数，$P\{X=k\}=\frac{C_{N_1}^kC_{N_2}^{n-k}}{C_N^n}$，$k=0,1,\dots,min{n,N_1}$。</li><li>不放回抽样实验，当N很大，n相对于N很小时，可以当作放回抽样试验。$P=\frac{M}{N}$改变小，即$\frac{n}{N}$小（N总数，M样本数），则$P=\{X=k\}=\frac{C_M^kC_{N-M}^{n-k}}{C_N^n}\approx C_n^kP^k(1-p)^{n-k}$。</li></ol><h3 id="随机变量的分布函数"><a href="#随机变量的分布函数" class="headerlink" title="随机变量的分布函数"></a>随机变量的分布函数</h3><ol><li>$F(x)=P\{X≤x\}(-\infty＜x＜\infty)$，称为X的分布函数（对于离散型，连续型都成立）。</li><li>$F(x)$是一个不减函数（或增或保持不变）；$0≤F(x)≤1$,即$F(-\infty)=\lim \limits_{x \to -\infty} F(x)=0$，$F(\infty)=\lim \limits_{x \to \infty} F(x)=1$。</li><li>$F(x)$对于离散型是右连续的（即$F(x+0)=F(x)$），$F(X)$对于连续型是连续的。</li></ol><h3 id="连续型随机变量及其概率密度"><a href="#连续型随机变量及其概率密度" class="headerlink" title="连续型随机变量及其概率密度"></a>连续型随机变量及其概率密度</h3><ol><li>非负可积$f(x)$，$f(x)≥0$,$a≤b$，则$P\{a&lt;x≤b\}=\int_a^bf(x){\rm d}x$，记为$X\sim f(x)$。连续型随机变量不注重端点值，且$f(x)≥0$，$\int_{-\infty}^\infty f(x){\rm d}x=1$。</li><li>对于任意$x_1≤x_2$，$P\{x_1&lt;X≤x_2\}=F(x_2)-F(x_1)=\int_{x_1}^{x_2}f(x){\rm d}x$。</li><li>若$f(x)$在点x处连续，则$F\prime(x)=f(x)$。</li><li>连续变量取个别值的概率为零。</li><li>均匀分布：$f(x)=\begin{cases} \frac{1}{b-a}，&amp;a&lt;x&lt;b，\\0，&amp;其他，\end{cases}$，记为$X\sim U(a, b)$。</li><li>指数分布：$f(x)=\begin{cases} \lambda e^{-\lambda x}，&amp;x&gt;0，\\0，&amp;x≤0，\end{cases}$，其中$\lambda &gt;0$，记为$X\sim Exp(\lambda)$。</li><li>正态分布（高斯分布）：$f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$，$-\infty&lt;x&lt;\infty$，记为$X\sim N(\mu, \sigma^2)$。当$x=\mu$时取得最大值。曲线关于$x=\mu$对称，对于任意$h&gt;0$都有$P\{\mu-h&lt;X≤\mu\}=P\{\mu&lt;X≤\mu+h\}$。$\sigma$固定，$\mu$变化，图像左右移动；$\mu$固定，$\sigma$变化，$\begin{cases} \sigma变小，最高点上移，图像变陡。\\\sigma变大，最高点下移，图像变缓。 \end{cases}$</li><li>标准正态分布$\phi_o(x)$：当$\mu=0$，$\sigma=1$时，$\phi_o(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}$。$\Phi_o(-x)=1-\Phi_o(x)$，$\phi_o(x)=\phi_o(-x)$。$\phi(x)=\frac{1}{\sigma}\phi_o(\frac{x-\mu}{\sigma})$。若$X\sim N(\mu, \sigma^2)$，则$Z=\frac{X-\mu}{\sigma}\sim N(0, 1)$。</li></ol><h3 id="随机变量的函数的分布"><a href="#随机变量的函数的分布" class="headerlink" title="随机变量的函数的分布"></a>随机变量的函数的分布</h3><ol><li>离散型：X代入函数，p不变。若X代入函数之后有相同值则合并（p相加）。</li><li>连续型：设X的$f_X(x)$，$y=g(x)$，$Y=g(X)$，则求解步骤为：<ul><li>得出$F_Y(x)$，$F_Y(x)=P\{Y≤x\}$，将其化成$F_X(x)$，$F_X(x)=P\{X≤x\}$。</li><li>对$F_Y(x)=F_X(x)$求导得$f_Y(x)=f_X(x)$，根据$f_X(x)$写出$f_Y(x)$的分段函数。</li></ul></li></ol><h2 id="多维随机变量及其分布"><a href="#多维随机变量及其分布" class="headerlink" title="多维随机变量及其分布"></a>多维随机变量及其分布</h2><h3 id="二维随机变量"><a href="#二维随机变量" class="headerlink" title="二维随机变量"></a>二维随机变量</h3><ol><li>联合分布函数：$F(x, y)$=$P\{(X≤x)\bigcap(Y≤y)\}$=$P\{X≤x, Y≤y\}$。</li><li>$F(x, y)$是不减h函数，y固定时，$x_1＜x_2$，$F(x_1, y)≤F(x_2, y)$。</li><li>$0≤F(x, y)≤1$，当y固定时$F(-\infty, y)=0$，$当x固定时F(x, -\infty)=0$，$F(-\infty, -\infty)=0$，$F(\infty, \infty)=1$。</li><li>对于任意$(x_1, y_1)$，$(x_2, y_2)$，$x_1&lt;x_2$，$y_1&lt;y_2$，则$F(x_2, y_2)-F(x_2, y_1)+F(x_1, y_1)-F(x_1, y_2)≥0$。</li></ol><h3 id="边缘分布"><a href="#边缘分布" class="headerlink" title="边缘分布"></a>边缘分布</h3><ol><li>离散型边缘分布：简单说就是确定$x_i$，将$x_i$所在的%y_j%概率相加，即为该$x_i$的边缘分布。</li><li>连续型边缘分布：$F(x, y)$=$P\{X≤x, Y≤y\}$=$\int_{-\infty}^x \int_{-\infty}^y f(s, t){\rm d}s{\rm d}t$，其中$F(x, y)$是联合分布，$f(x, y)$是联合密度。G是XY平面上的一个区域，$P\{(X, Y)∈G\}$=${\int \int}_G f(x, y){\rm d}x{\rm d}y$。</li><li>联合分布可唯一确认边缘分布；边缘分布不能确定联合分布；当X，Y独立时，边缘分布才能确定联合分布。</li><li>边缘密度函数：已知$f(x, y)$，求$f_X(x)=\int_{-\infty}^{+\infty} f(x, y){\rm d}y$，$f_Y(x)=\int_{-\infty}^{+\infty} f(x, y){\rm d}x$，且$f(x, y)$=$f_X(x)f_Y(y)$。</li><li>二维正态分布的边缘分布也是正态。</li><li>两边缘分布是正态的，二维并非一定是二维正态的。</li></ol><h3 id="条件分布"><a href="#条件分布" class="headerlink" title="条件分布"></a>条件分布</h3><ol><li>条件分布：$P\{X=x_i|Y=y_j\}$=$\frac{P\{X=x_i, Y=y_j\}}{P\{Y=y_j\}}$=$\frac{P_{ij}}{P_j}$。</li><li>离散型的条件分布即$\frac{某点概率}{边缘分布概率}$。</li><li>连续型的条件分布：$(X, Y)$，$f(x, y)$，$f_X(x)$，$f_Y(y)$，若$f_Y(y)&gt;0$，在$Y=y$的条件下，$F(x|y)=\int_{-\infty}^x \frac{f(x, y)}{f_Y(y)}{\rm d}y$。</li></ol><h3 id="相互独立的随机变量"><a href="#相互独立的随机变量" class="headerlink" title="相互独立的随机变量"></a>相互独立的随机变量</h3><ol><li>二维离散型的独立性：$P_{ij}=x_iy_j$。</li><li>二维连续型的独立性：$f(x, y)=f_X(x)f_Y(y)$。</li><li>变量独立，则变量构造的函数也独立。</li></ol><h3 id="两个随机变量的函数的分布"><a href="#两个随机变量的函数的分布" class="headerlink" title="两个随机变量的函数的分布"></a>两个随机变量的函数的分布</h3><ol><li>二维离散型的函数分布：X和Y代入函数，求XY相乘所有的可能，p不变，若有重复的则合并（p相加）。</li><li>二维连续型的函数分布：$(X, Y)$，$f(x, y)$，$Z=g(X, Y)$，$F(\xi)=P\{Z≤\xi\}=P\{g(X, Y)≤\xi\}={\int\int}_{D_\xi} f(x, y){\rm d}x{\rm d}y$，求出$f_Z(\xi)$。</li><li>卷积公式：$f_X*f_Y=f_{X+Y}(z)=\int_{-\infty}^{\infty}f_X(z-y)f_Y(y){\rm d}y=\int_{-\infty}^{\infty}f_X(x)f_Y(z-x){\rm d}x$。</li><li>$Z=\frac{Y}{X}$：$f_{\frac{Y}{X}}(z)=\int_{-\infty}^{\infty}|x|f_X(x)f_Y(xz){\rm d}x$。</li><li>$Z=XY$：$f_{XY}(z)=\int_{-\infty}^{\infty}\frac{1}{|x|}f_X(x)f_Y(\frac{z}{x}){\rm d}x$。</li><li>$M=max\{X, Y\}$：$F_{max}(z)=F_X(z)F_Y(z)$。</li><li>$N=min\{X, Y\}$：$F_{min}(z)=1-[1-F_X(z)][1-F_Y(z)]$。</li></ol><h2 id="随机变量的数字特征"><a href="#随机变量的数字特征" class="headerlink" title="随机变量的数字特征"></a>随机变量的数字特征</h2><h3 id="数学期望"><a href="#数学期望" class="headerlink" title="数学期望"></a>数学期望</h3><ol><li>离散型的期望：若分布律为$P\{X=x_k\}=P_k$，$EX=\sum_{k=1}^\infty x_kP_k$（$EX$或$E(X)$数学期望），离散型的期望即值乘以概率值相加。</li><li>连续型的期望：若概率密度为$\int_{-\infty}^{\infty} xf(x){\rm d}x$，$EX=\int_{-\infty}^{\infty} xf(x){\rm d}x$。</li><li>离散型函数的期望：$Y=g(X)$，则$EY=\sum_{k=1}^\infty g(x_k)P_k$。</li><li>连续型函数的期望：$Y=g(X)$，则$EY=\int_{-\infty}^{\infty} g(x)f(x){\rm d}x$。</li><li>二维离散型函数的期望：$Z=g(X, Y)$，则$EZ=\sum_i\sum_j g(x_i, y_j)P_{ij}$。</li><li>二维连续型函数的期望：$Z=g(X, Y)$，则$EZ=\int_{-\infty}^\infty\int_{-\infty}^\infty g(x, y)f(x, y){\rm d}x{\rm d}y$。</li><li>期望的性质：$\begin{cases} EC=C\\E(X+C)=EX+C\\E(CX)=CEX\\E(kX+b)=kEX+b\\E(X±Y)=EX±EY\\若X，Y独立，E(XY)=EX EY \end{cases}$</li><li>条件期望：一个变量取某值，另一个变量的期望。$\begin{cases} E(X|Y=y_j)=\sum x_iP(X=x_i|Y=y_j)&amp;离散型\\E(X|Y=y)=\int_{-\infty}^\infty xf(x|y){\rm d}x&amp;连续型 \end{cases}$。</li></ol><h3 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h3><ol><li>方差：即随机变量与期望偏离的程度，记为$DX=E(X-EX)^2=EX^2-(EX)^2$，量纲$\sqrt{DX}$。</li><li>离散型方差：$DX=\sum_k (x_k-EX)^2P_k$。</li><li>连续型方差：$DX=\int_{-\infty}^\infty (x-EX)^2f(x){\rm d}x$。</li><li>方差的性质：$\begin{cases} DC=0\\D(X+C)=DX\\D(CX)=C^2DX\\D(kX+b)=k^2DX\\若X，Y独立，D(X±Y)=DX+DY\\DX=0\Leftrightarrow P(X=EX)=1 \end{cases}$</li><li>若$X^\ast=\frac{X-EX}{\sqrt{DX}}$，则$EX^\ast=0$，$DX^\ast=1$。</li><li>$(0-1)$分布的期望与方差：$EX=p$，$DX=p(1-p)$。</li><li>二项分布的期望与方差：$EX=np$，$DX=np(1-p)$。</li><li>几何分布的期望与方差：$EX=\frac{1}{p}$，$DX=\frac{1-p}{p^2}$。</li><li>泊松分布的期望与方差：$EX=\lambda$，$DX=\lambda$。</li><li>均匀分布的期望与方差：$EX=\frac{a+b}{2}$，$DX=\frac{(b-a)^2}{12}$。</li><li>指数分布的期望与方差：$EX=\frac{1}{\lambda}$，$DX=\frac{1}{\lambda^2}$。</li><li>正态分布的期望与方差：$EX=\mu$，$DX=\sigma^2$。</li></ol><h3 id="协方差及相关系数"><a href="#协方差及相关系数" class="headerlink" title="协方差及相关系数"></a>协方差及相关系数</h3><ol><li>协方差：$Cov(X, Y)=E[(X-EX)(Y-EY)]=E(XY)-EXEY$。</li><li>$D(X±Y)=DX+DY±2Cov(X, Y)$。</li><li>协方差相关性质：$\begin{cases} Cov(X, Y)=Cov(Y, X)\\Cov(aX, bY)=abCov(X, Y)\\Cov(X_1+X_2, Y)=Cov(X_1, Y)+Cov(X_2, Y)\\Cov(C, X)=0\\若X，Y独立，Cov(X, Y)=0 \end{cases}$。</li><li>标准化：若$X^\ast=\frac{X-EX}{\sqrt{DX}}$，$Y^\ast=\frac{Y-EY}{\sqrt{DY}}$，则$Cov(X^\ast, Y^\ast)=\rho=\frac{Cov(X, Y)}{\sqrt{DX}\sqrt{DY}}$。</li><li>相关系数：$\begin{cases} |\rho|≤1\\ [E(XY)]^2≤EX^2EY^2\\|\rho|=1\Leftrightarrow P\{Y=a+bX\}=1，即XY成线性关系 \end{cases}$</li><li>$\rho=1$则X，Y完全正相关；$\rho=-1$则X，Y完全负相关；$|\rho|$接近0则X，Y线性关系不弱；$\rho=0$则X，Y不存在线性关系。</li><li>X，Y独立则X，Y不相关；X，Y不相关则X，Y不一定独立。独立与不相关是等价的。</li></ol><h3 id="矩、协方差矩阵"><a href="#矩、协方差矩阵" class="headerlink" title="矩、协方差矩阵"></a>矩、协方差矩阵</h3><ol><li>原点矩：$EX^k$，以原点为中心；中心距：$E(X-EX)^k$，以期望为中心。</li><li>离散型原点矩：$\sum x_i^kP_i$。</li><li>离散型中心距：$\int_{-\infty}{\infty}x^kf(x){\rm d}x$。</li><li>连续型原点矩：$\sum (x_i-EX)^kP_i$。</li><li>连续型中心距：$\int_{-\infty}{\infty}(x-EX)^kf(x){\rm d}x$。</li></ol><h2 id="大数定律及中心极限定理"><a href="#大数定律及中心极限定理" class="headerlink" title="大数定律及中心极限定理"></a>大数定律及中心极限定理</h2><h3 id="大数定律"><a href="#大数定律" class="headerlink" title="大数定律"></a>大数定律</h3><ol><li>切比雪夫大数定理：$X_1,\dots,X_n$不相关的变量，$EX_i$和$DX_i$都存在，方差有界，即$DX_i≤M$，对$\forall \epsilon&gt;0$时，有$\lim \limits_{n \to \infty} P\{|\frac{1}{n}\sum_{i=1}^nX_i-\frac{1}{n}\sum_{i=1}^nEX_i|&lt;\epsilon\}=1$。</li><li>伯努利大数定理：假设n重伯努利试验，事件A发生了m次，P是其发生概率，$\frac{m_n}{n}$即为其频率，当$n \to \infty$时，即$\lim \limits_{n \to \infty}P\{|\frac{m_n}{n}-P|&lt;\epsilon\}=1$，其概率依概率收敛于它的概率。也有$\lim \limits_{n \to +\infty}P\{|\frac{m_n}{n}-P|≥\epsilon\}=0$。</li><li>辛钦大数定理：$X_1,\dots,X_n$独立同分布，且$EX_i=M$，$DX_i=\sigma^2$，有$\forall \epsilon&gt;0$，则$\lim \limits_{n \to \infty} P\{|\frac{1}{n}\sum_{i=1}^nX_i-\mu|&lt;\epsilon\}=1$。</li></ol><h3 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h3><ol><li>$X_1,\dots,X_n$独立同分布，$EX_i=\mu$，$DX_i=\sigma^2$，$0&lt;\sigma^2&lt;+\infty$，$\lim \limits_{n \to \infty}F_n(x)$=$\lim \limits_{n \to \infty}P\{\frac{\sum_{k=1}^nX_k-n\mu}{\sqrt{n}\sigma}≤x\}$=$\int_{-\infty}^x\frac{1}{\sqrt{2\pi}}e^{-\frac{t^2}{2}}{\rm d}t$=$\Phi(x)$。当n充分大时，$\frac{\sum x_i-n\mu}{\sqrt{n}\sigma}\sim N(0, 1)$，$\sum_{i=1}^nX_i\sim N(n\mu, n\sigma^2)$。</li><li>$Y_n$，n，p二项分布近似正态分布，$\Phi_o(x)=\lim \limits_{n \to \infty}P\{\frac{Y_n-np}{\sqrt{np(1-p)}}≤x\}$，其中$Y_n=\sum_{i=1}^nX_i$，$X_i=\begin{cases} 1&amp;发生\\0&amp;未发生 \end{cases}$，$EX_i=P$，$DX_i=p(1-P)$。</li></ol><h2 id="样本及抽样分布"><a href="#样本及抽样分布" class="headerlink" title="样本及抽样分布"></a>样本及抽样分布</h2><h3 id="随机样本"><a href="#随机样本" class="headerlink" title="随机样本"></a>随机样本</h3><p>$X:(0-1)分布$：$P(X_1=x_1,\dots,X_n=x_n)$=$P(X_1=x_1)\dots P(X_n=x_n)$=$P^{x_1}(1-p)^{1-x_1}\dots P^{x_n}(1-p)^{1-x_n}$=$P^{x_1+\dots+x_n}(1-p)^{n-(x_1+\dots +x_n)}$。</p><h3 id="抽样分布"><a href="#抽样分布" class="headerlink" title="抽样分布"></a>抽样分布</h3><ol><li>统计量：不含任何未知参数的样本构造的函数。</li><li>样本平均值：$\hat{X}=\frac{1}{n}\sum_{i=1}^nX_i$。</li><li>未修正样本方差：$S_o^2=\frac{1}{n}\sum_{i=1}^n(X_i-\hat{X})^2$。$S^2=\frac{n}{n-1}S_o^2$。</li><li>样本方差：$S^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\hat{X})^2$。</li><li>样本标准方差：$S=\sqrt{S^2}$。</li><li>样本k阶（原点）矩：$A_k=\frac{1}{n}\sum_{i=1}^nX_i^k,(k=1,2,\dots)$。$A_1=\hat{X}$。</li><li>样本k阶中心距：$B_k=\frac{1}{n}\sum_{i=1}^n(X_i-\hat{X})^k,(k=2,3,\dots)$。$B_2=S_o^2$。$S^2=\frac{n}{n-1}B_2$。</li><li>协方差：$S_{1,2}=\frac{1}{n}(X_i-\hat{X})(Y_i-Y)$。</li><li>两样本之间的相关系数：$R=\frac{S_{1,2}}{S_1S_2}$。</li><li>总体X的均值为$EX=\mu$，方差为$DX=\sigma^2$，样本（$X_1,X_2,\dots,X_n$）来自总体X，则$E\hat{X}=\mu$，$D\hat{X}=\frac{1}{n}\sigma^2$，$ES^2=\sigma^2$。</li><li>卡方分布：<ul><li>$X_1,\dots,X_n$独立且是来自$N(0, 1)$的样本，则$\chi^2=\sum_{i=1}^nx_i^2\sim \chi^2(n)$。</li><li>$EX=n$，$DX=2n$。</li><li>由中心极限定理得$X\sim \chi^2(n)$，$Y\sim \chi^2(m)$，X, Y独立，则$X+Y\sim \chi^2(m+n)$。</li><li>$X_i\sim \chi^2(m_i)$，独立，$\sum_{i=1}^nX_i\sim \chi^2(\sum_{i=1}^nm_i)$。</li><li>上$\alpha$分位数：$P(\chi^2&gt;\chi^2_alpha(n))=\alpha$。$\chi^2$相当于变量，$\chi^2_alpha(n)$相当于一个点，$\alpha$相当于面积。</li><li>$\chi^2(2)$是$\lambda=\frac{1}{2}$的指数分布。</li><li>$\chi^2(n)$是单峰曲线，在$n-2$时取得最大值。</li><li>当$n=2$时曲线不对称，当n增大图像越接近对称，且在n很大时，可用正态分布近似。</li></ul></li><li>t分布：<ul><li>若$X\sim N(0, 1)$，$Y\sim \chi^2(n)$，X, Y独立，则$t(n)\sim\frac{X}{\sqrt{\frac{Y}{n}}}$。</li><li>上$\alpha$分位数：$P(T&gt;t_\alpha(n))=\alpha$。</li><li>$t_{1-\alpha}(n)$=$-t_\alpha(n)$。</li><li>n越小，其图像与正态分布差距越大（$n≥30$，与正态分布区别很小）。</li></ul></li><li>F分布：<ul><li>$X\sim \chi^2(n_1)$，$Y\sim \chi^2(n_2)$，X, Y独立，$F(n_1, n_2)\sim \frac{\frac{X}{n_1}}{\frac{Y}{n_2}}$。</li><li>$\frac{1}{F}\sim F(n_2, n_1)$。</li><li>上$\alpha$分位数：$P(F&gt;F_\alpha(n_1, n_2)=\alpha$。</li><li>$F_{1-\alpha}(n_1, n_2)=\frac{1}{F_\alpha(n_2, n_1)}$。</li></ul></li><li>正态总体下的抽样分布：<ul><li>$X\sim N(\mu, \sigma^2)$，$\{X_1,\dots,X_n\}$样本，则$E\hat{X}=\mu$，$D\hat{X}=\frac{\sigma^2}{n}$，$\frac{\hat{X}-\mu}{\sigma}\sqrt{n}\sim N(0, 1)$，即$E(S^2)=\sigma^2$。</li><li>$\hat{X}\sim N(\mu, \frac{\sigma^2}{n})$。</li><li>$\frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1)$，$\hat{X}$与$S^2$独立。</li><li>$\frac{1}{\sigma^2}\sum_{i=1}^n(X_i-\mu)^2\sim \chi^2(n)$。</li><li>$\frac{\hat{X}-\mu}{S}\sqrt{n}\sim t(n-1)$。</li><li>两个正态总体：$X\sim N(\mu_1, \sigma_1^2)$，$Y\sim N(\mu_2, \sigma_2^2)$，样本$\{X_1,\dots,X_{n_1}\}$，$\{Y_1,\dots,Y_{n_2}\}$，$\begin{cases} \frac{(\hat{X}-\hat{Y})-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}\sim N(0, 1)\\\frac{\frac{S_1^2}{\sigma_1^2}}{\frac{S_2^2}{\sigma_2^2}}\sim F(n_1-1, n_2-1)\\ \sigma_1^2=\sigma_2^2=\sigma 时，T=\frac{(\hat{X}-\hat{Y})-(\mu_1-\mu_2)}{\sqrt{\frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}}\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}\sim t(n_1+n_2-2) \end{cases}$</li></ul></li></ol><h2 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h2><h3 id="点估计"><a href="#点估计" class="headerlink" title="点估计"></a>点估计</h3><ol><li>点估计：通过一个样本估计总体未知参数。</li><li>矩估计法：以样本矩的连续函数作为相应的总体矩的连续函数的估计量。$A_n=\frac{1}{n}\sum X_i^2$。</li><li>极大似然估计法：<ul><li>1.写出总体的概率函数或密度函数。</li><li>2.写出似然函数$L(\lambda)=\prod_{i=1}^2\frac{\lambda^{x_i}}{x_i!}e^{-\lambda}$（此处以泊松分布为例，似然函数即将样本观测值代入1.式并连乘）。</li><li>3.需使似然函数取最大值，两边取$ln$。</li><li>4.对$\lambda$求导（此处$\lambda$根据概率函数或者密度函数改变）。</li></ul></li></ol><h3 id="估计量的评选标准"><a href="#估计量的评选标准" class="headerlink" title="估计量的评选标准"></a>估计量的评选标准</h3><ol><li>无偏性：<ul><li>估计的参数的估计值的期望是其真实的值，即$E\hat{\theta}=\theta$。</li><li>总体$X$，$EX=\mu$，$DX=\sigma^2$，$(X_1,\dots,X_n)$，总体与任何分布无关，则$\begin{cases}\hat{X}是\mu的无偏估计，E\hat{X}=\mu。\\样本方差S^2是\sigma^2的无偏估计，ES^2=\sigma^2。\\未修正样本方差S_o^2是\sigma^2的有偏估计。\\n \to \infty，渐进无偏估计。\\ \hat{\theta}是\theta的无偏估计，g(\hat{\theta})不一定是g(\theta)的无偏估计。\\DS=\sigma^2-(ES)^2，ES=\sqrt{\sigma^2-DS}≤\sigma（一般不等于）。 \end{cases}$</li></ul></li><li>有效性：$D(\hat{\theta}_1)≤D(\hat{\theta}_2)$，方差越小越有效。</li><li>相合性（一致性）：$\lim \limits_{n \to +\infty}P(|\hat{\theta}-\theta|&lt;\epsilon)=1$。</li></ol><h3 id="区间估计"><a href="#区间估计" class="headerlink" title="区间估计"></a>区间估计</h3><ol><li>置信区间：$[\hat{\theta_1},\hat{\theta_2}]$能套住$\theta$的概率，即以区间估计的区域套住$\theta$的概率。</li><li>枢轴变量：即通过先确定两个数来确定未知数。<ul><li>$I=I(T, \theta)$，其中$T$已知，$\theta$未知，枢轴变量I的分布F已知且与$\theta$无关。</li><li>给定$1-\alpha$，确定F分布的上$$分位数，上$$分位数，即$P\{V_{1-\frac{\alpha}{2}}≤I(T, \theta)≤V_{\frac{\alpha}{2}}\}=1-\alpha$。</li></ul></li></ol><h3 id="正态总体均值与方差的区间估计"><a href="#正态总体均值与方差的区间估计" class="headerlink" title="正态总体均值与方差的区间估计"></a>正态总体均值与方差的区间估计</h3><ol><li>若给定置信水平$1-\alpha$，$X_1,\dots,X_n$为$N(\mu, \sigma^2)$的样本，已知$\hat{X}$，$S^2$。<ul><li>$\sigma^2$已知，枢轴变量$\frac{\hat{X}-\mu}{\frac{\sigma}{\sqrt{n}}}$，$1-\alpha$的置信区间$(\hat{X}±\frac{\sigma}{\sqrt{n}}z_{\frac{\alpha}{2}})$。</li><li>$\sigma^2$未知，枢轴变量$\frac{\hat{X}-\mu}{\frac{\sigma}{\sqrt{n}}}\sim t(n-1)$，$1-\alpha$的置信区间$(\hat{X}±\frac{S}{\sqrt{n}}t_{\frac{\alpha}{2}}(n-1))$。</li></ul></li><li>单个总体$N(\mu, \sigma^2)$情况表<table><thead><tr><th>估计表</th><th></th><th></th><th></th></tr></thead><tbody><tr><td>$\mu$</td><td>$\sigma^2$已知</td><td>$\frac{\hat{X}-\mu}{\sigma}\sqrt{n}\sim N(0, 1)$</td><td>$[\hat{X}-\frac{\sigma}{\sqrt{n}}\mu_{\frac{\alpha}{2}}, \hat{X}+\frac{\sigma}{\sqrt{n}}\mu_{\frac{\alpha}{2}}]$</td></tr><tr><td>$\mu$</td><td>$\sigma^2$未知</td><td>$\frac{\hat{X}-\mu}{S}\sqrt{n}\sim t(n-1)$</td><td>$[\hat{X}-\frac{S}{\sqrt{n}}t_{\frac{\alpha}{2}}(n-1), \hat{X}+\frac{S}{\sqrt{n}}t_{\frac{\alpha}{2}}(n-1)]$</td></tr><tr><td>$\sigma^2$</td><td>$\mu$已知</td><td>$\frac{1}{\sigma^2}\sum_{i=1}^n(X_i-\mu)^2\sim \chi^2(n)$</td><td>$[\frac{\sum(X_i-\mu)^2}{\chi^2_{\frac{\alpha}{2}}(n)}, \frac{\sum(X_i-\mu)^2}{\chi^2_{1-\frac{\alpha}{2}}(n)}]$</td></tr><tr><td>$\sigma^2$</td><td>$\mu$未知</td><td>$\frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1)$</td><td>$[\frac{(n-1)S^2}{\chi^2_{\frac{\alpha}{2}}(n-1)}, \frac{(n-1)S^2}{\chi^2_{1-\frac{\alpha}{2}}(n-1)}]$</td></tr></tbody></table></li></ol><script>document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });</script></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="https://blog.kuukokawaii.com" rel="external nofollow noreferrer">喵粮都输光了</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://blog.kuukokawaii.com/posts/28d5cef4/">https://blog.kuukokawaii.com/posts/28d5cef4/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.kuukokawaii.com" target="_blank">喵粮都输光了</a> !</span></div></div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/%E6%95%B0%E5%AD%A6/"><span class="chip bg-color">数学</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/share/js/social-share.min.js"></script></div></div></div></div></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/gitalk/gitalk.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/css/my-gitalk.css"><div class="card gitalk-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="gitalk-container" class="card-content"></div></div><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/gitalk/gitalk.min.js"></script><script>let gitalk = new Gitalk({
        clientID: 'd5486fd8d317f4dc0523',
        clientSecret: '8b650ba460c20493d62aac30581f44c1c98fd9b5',
        repo: 'nanahana.github.io',
        owner: 'nana-hana',
        admin: "nana-hana",
        id: '2020-03-07T18-50-02',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/168b5985/"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/medias/loading.gif" alt="" data-original="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/medias/featureimages/19.jpg" class="responsive-img" alt="设计模式之观察者模式"> <span class="card-title">设计模式之观察者模式</span></div></a><div class="card-content article-content"><div class="summary block-with-text">当对象间存在一对多关系时，常使用观察者模式。观察者模式属于行为型模式。<br><br><br></div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-03-09 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" class="post-category">设计模式</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"><span class="chip bg-color">设计模式</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/93e4730e/"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/medias/loading.gif" alt="" data-original="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/medias/featureimages/17.jpg" class="responsive-img" alt="高等数学"> <span class="card-title">高等数学</span></div></a><div class="card-content article-content"><div class="summary block-with-text">高等数学知识点总结。<br><br><br></div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-03-02 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%95%B0%E5%AD%A6/" class="post-category">数学</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E6%95%B0%E5%AD%A6/"><span class="chip bg-color">数学</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["(",")"]]}})</script><footer class="page-footer bg-color"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/aplayer/APlayer.min.css"><style>.aplayer .aplayer-lrc p{font-size:12px;font-weight:700;line-height:16px!important}.aplayer .aplayer-lrc p.aplayer-lrc-current{font-size:15px;color:#BE74EC}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body{left:-66px!important}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover{left:0!important}</style><div><div class="row"><meting-js class="col l8 offset-l2 m10 offset-m1 s12" server="netease" type="playlist" id="2215112986" fixed="true" autoplay theme="#BE74EC" loop order="random" preload="auto" volume="0.1" list-folded="true"></meting-js></div></div><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/aplayer/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2019</span> <a href="https://blog.kuukokawaii.com" target="_blank">喵粮都输光了</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">116.9k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="mailto:na@kuukokawaii.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50"><i class="fas fa-rss"></i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://blog.kuukokawaii.com/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/js/matery.js"></script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-152985184-1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-152985184-1")</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?cf000f141067bb5e00a4f0dbf60fae4e";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script>!function(){var t=document.createElement("script"),s=window.location.protocol.split(":")[0];"https"===s?t.src="https://zz.bdstatic.com/linksubmit/push.js":t.src="http://push.zhanzhang.baidu.com/push.js";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/others/clicklove.js" async></script><script async src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/others/busuanzi.pure.mini.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/background/ribbon-dynamic.js" async></script><script src="https://cdn.jsdelivr.net/gh/nana-hana/blog.source@latest/libs/instantpage/instantpage.js" type="module"></script><script>!function(t){function n(){for(var n=0;n<e.length;n++)i=e[n],0<=(o=i.getBoundingClientRect()).bottom&&0<=o.left&&o.top<=(t.innerHeight+240||document.documentElement.clientHeight+240)&&function(){var t,i,o,r,c=e[n];t=c,i=function(){e=e.filter(function(t){return c!==t})},o=new Image,r=t.getAttribute("data-original"),o.onload=function(){t.src=r,i&&i()},o.src=r}();var i,o}var e=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));n(),t.addEventListener("scroll",function(){var e,i;e=n,i=t,clearTimeout(e.tId),e.tId=setTimeout(function(){e.call(i)},500)})}(this)</script><script>window.addEventListener("load",function(){var a=/\.(gif|jpg|jpeg|tiff|png)$/i,e=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(t){var r=t.parentNode;"A"===r.tagName&&(r.href.match(a)||r.href.match(e))&&(r.href=t.dataset.original)})})</script></body></html><!-- rebuild by neat -->